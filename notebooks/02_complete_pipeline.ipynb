{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Beta Portfolio Strategy - Complete Pipeline\n",
    "\n",
    "This notebook demonstrates the complete pipeline from data fetching to portfolio construction and backtesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "from data_collection.data_fetcher import DataFetcher\n",
    "from factor_construction.factor_builder import FactorBuilder\n",
    "from models.ml_models import MLModels\n",
    "from models.lstm_model import LSTMModel\n",
    "from portfolio_optimization.optimizer import PortfolioOptimizer\n",
    "from backtesting.backtest import Backtest\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data fetcher\n",
    "fetcher = DataFetcher()\n",
    "\n",
    "# Get S&P 500 tickers\n",
    "sp500_tickers = fetcher.get_sp500_tickers()\n",
    "print(f\"Fetched {len(sp500_tickers)} S&P 500 tickers\")\n",
    "\n",
    "# Fetch stock data (using a subset for demonstration)\n",
    "selected_tickers = sp500_tickers[:50]  # Top 50 stocks\n",
    "stock_data = fetcher.fetch_stock_data(selected_tickers, start_date='2020-01-01', end_date='2023-12-31')\n",
    "print(f\"Stock data shape: {stock_data.shape}\")\n",
    "\n",
    "# Fetch benchmark data\n",
    "benchmark_data = fetcher.fetch_benchmark_data('SPY', start_date='2020-01-01', end_date='2023-12-31')\n",
    "print(f\"Benchmark data shape: {benchmark_data.shape}\")\n",
    "\n",
    "# Calculate returns\n",
    "stock_returns = fetcher.calculate_returns(stock_data)\n",
    "benchmark_returns = fetcher.calculate_returns(benchmark_data)\n",
    "\n",
    "print(\"\\nData collection completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Factor Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize factor builder\n",
    "factor_builder = FactorBuilder(stock_data, stock_returns)\n",
    "\n",
    "# Calculate all factors\n",
    "factors_df = factor_builder.calculate_all_factors()\n",
    "print(f\"Factors calculated: {factors_df.shape}\")\n",
    "print(f\"Factor columns: {list(factors_df.columns)}\")\n",
    "\n",
    "# Normalize factors\n",
    "factors_normalized = factor_builder.normalize_factors(factors_df, method='zscore')\n",
    "\n",
    "# Get factor statistics\n",
    "factor_stats = factor_builder.get_factor_statistics(factors_normalized)\n",
    "print(\"\\nFactor Statistics:\")\n",
    "print(factor_stats.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare target variable (using benchmark returns as target)\n",
    "target_returns = benchmark_returns['SPY']\n",
    "\n",
    "# Initialize ML models\n",
    "ml_models = MLModels(factors_normalized, target_returns, test_size=0.2)\n",
    "\n",
    "# Train all models\n",
    "ml_models.train_all_models()\n",
    "\n",
    "# Get model comparison\n",
    "model_comparison = ml_models.get_model_comparison()\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(model_comparison)\n",
    "\n",
    "# Get feature importance for best model\n",
    "best_model = model_comparison.index[0]\n",
    "feature_importance = ml_models.get_feature_importance(best_model)\n",
    "print(f\"\\nFeature Importance ({best_model}):\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: LSTM Model (Optional Deep Learning Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LSTM model\n",
    "lstm_model = LSTMModel(sequence_length=30, test_size=0.2)\n",
    "\n",
    "# Prepare data for LSTM\n",
    "lstm_model.prepare_data(factors_normalized, target_returns)\n",
    "\n",
    "# Build LSTM model\n",
    "lstm_model.build_model(lstm_units=[64, 32], dropout_rate=0.2, learning_rate=0.001)\n",
    "\n",
    "# Train LSTM model\n",
    "history = lstm_model.train_model(epochs=50, batch_size=32, patience=10)\n",
    "\n",
    "# Evaluate LSTM model\n",
    "lstm_results = lstm_model.evaluate_model()\n",
    "print(\"\\nLSTM Model Results:\")\n",
    "for metric, value in lstm_results.items():\n",
    "    print(f\"{metric}: {value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Portfolio Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from best ML model\n",
    "predictions = ml_models.predict_returns(best_model)\n",
    "\n",
    "# Use predictions to create expected returns (simplified approach)\n",
    "# In practice, you would use predictions to form expected returns for optimization\n",
    "expected_returns = stock_returns.mean()  # Using historical means for demonstration\n",
    "\n",
    "# Initialize portfolio optimizer\n",
    "optimizer = PortfolioOptimizer(stock_returns)\n",
    "\n",
    "# Calculate optimal portfolios\n",
    "max_sharpe_weights = optimizer.maximum_sharpe_ratio(risk_free_rate=0.02)\n",
    "min_var_weights = optimizer.minimum_variance()\n",
    "\n",
    "print(\"Portfolio Optimization Results:\")\n",
    "print(f\"Max Sharpe portfolio: {len(max_sharpe_weights)} assets\")\n",
    "print(f\"Min Variance portfolio: {len(min_var_weights)} assets\")\n",
    "\n",
    "# Calculate efficient frontier\n",
    "efficient_frontier = optimizer.efficient_frontier(num_points=30)\n",
    "print(f\"\\nEfficient frontier calculated with {len(efficient_frontier)} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create portfolio weights DataFrame (using max Sharpe weights)\n",
    "portfolio_weights = pd.DataFrame(\n",
    "    index=stock_data.index,\n",
    "    columns=stock_data.columns,\n",
    "    data=np.tile(max_sharpe_weights, (len(stock_data), 1))\n",
    ")\n",
    "\n",
    "# Initialize backtest\n",
    "backtest = Backtest(stock_data, portfolio_weights, risk_free_rate=0.02)\n",
    "\n",
    "# Run backtest\n",
    "portfolio_returns = backtest.run_backtest()\n",
    "\n",
    "# Calculate performance metrics\n",
    "performance_metrics = backtest.calculate_performance_metrics(portfolio_returns)\n",
    "\n",
    "print(\"\\nBacktest Results:\")\n",
    "for metric, value in performance_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Compare with benchmark\n",
    "benchmark_perf = backtest.calculate_performance_metrics(benchmark_returns['SPY'])\n",
    "print(\"\\nBenchmark (SPY) Results:\")\n",
    "for metric, value in benchmark_perf.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualization and Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "model_comparison['test_r2'].plot(kind='bar')\n",
    "plt.title('Model Comparison - Test R²')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.subplot(2, 2, 2)\n",
    "feature_importance.head(10).set_index('feature')['importance'].plot(kind='bar')\n",
    "plt.title('Top 10 Feature Importance')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Plot efficient frontier\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(efficient_frontier['volatility'], efficient_frontier['return'], c=efficient_frontier['sharpe_ratio'], cmap='viridis')\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('Expected Return')\n",
    "plt.title('Efficient Frontier')\n",
    "\n",
    "# Plot cumulative returns comparison\n",
    "plt.subplot(2, 2, 4)\n",
    "portfolio_cumulative = (1 + portfolio_returns).cumprod()\n",
    "benchmark_cumulative = (1 + benchmark_returns['SPY']).cumprod()\n",
    "\n",
    "plt.plot(portfolio_cumulative.index, portfolio_cumulative.values, label='Smart Beta Portfolio', linewidth=2)\n",
    "plt.plot(benchmark_cumulative.index, benchmark_cumulative.values, label='S&P 500 (SPY)', linewidth=2)\n",
    "plt.legend()\n",
    "plt.title('Cumulative Returns Comparison')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Return')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrame\n",
    "summary_data = {\n",
    "    'Metric': ['Total Return', 'Annualized Return', 'Annualized Volatility', 'Sharpe Ratio', 'Max Drawdown'],\n",
    "    'Smart Beta Portfolio': [\n",
    "        f\"{performance_metrics['total_return']:.2%}\",\n",
    "        f\"{performance_metrics['annualized_return']:.2%}\",\n",
    "        f\"{performance_metrics['annualized_volatility']:.2%}\",\n",
    "        f\"{performance_metrics['sharpe_ratio']:.3f}\",\n",
    "        f\"{performance_metrics['max_drawdown']:.2%}\"\n",
    "    ],\n",
    "    'S&P 500 Benchmark': [\n",
    "        f\"{benchmark_perf['total_return']:.2%}\",\n",
    "        f\"{benchmark_perf['annualized_return']:.2%}\",\n",
    "        f\"{benchmark_perf['annualized_volatility']:.2%}\",\n",
    "        f\"{benchmark_perf['sharpe_ratio']:.3f}\",\n",
    "        f\"{benchmark_perf['max_drawdown']:.2%}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SMART BETA PORTFOLIO STRATEGY - FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Key insights\n",
    "print(\"\\nKEY INSIGHTS:\")\n",
    "print(f\"• Best performing ML model: {best_model} (R² = {model_comparison.loc[best_model, 'test_r2']:.4f})\")\n",
    "print(f\"• Number of factors generated: {len(factors_df.columns)}\")\n",
    "print(f\"• Portfolio optimization method: Maximum Sharpe Ratio\")\n",
    "print(f\"• Backtest period: {stock_data.index[0].strftime('%Y-%m-%d')} to {stock_data.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"• Total assets in portfolio: {len(selected_tickers)}\")\n",
    "\n",
    "# Performance comparison\n",
    "excess_return = performance_metrics['annualized_return'] - benchmark_perf['annualized_return']\n",
    "print(f\"\\nPERFORMANCE vs BENCHMARK:\")\n",
    "print(f\"• Excess annualized return: {excess_return:.2%}\")\n",
    "print(f\"• Risk-adjusted performance (Sharpe): {performance_metrics['sharpe_ratio'] - benchmark_perf['sharpe_ratio']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PIPELINE EXECUTION COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
